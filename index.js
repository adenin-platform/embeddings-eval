const fs = require('fs').promises;
const path = require('path');
require('dotenv').config();
const { LocalIndex } = require('vectra');
const EmbeddingService = require('./lib/embedding');
const Generator = require('./lib/generate');
const Validator = require('./lib/validate');
const Metrics = require('./lib/metrics');

class EmbeddingsEvaluator {
  constructor(dataset = 'default', modelName = 'default') {
    this.dataset = dataset;
    this.modelName = modelName;
    this.datasetPath = path.join(__dirname, dataset);
    this.indexPath = path.join(this.datasetPath, 'embeddings');
    this.index = null;
    this.modelConfig = null;
    this.metrics = new Metrics();
    this.apiKey = null;
    this.embeddingService = null;
  }

  async loadModelConfig() {
    try {
      const modelConfigPath = path.join(__dirname, `${this.modelName}-model.json`);
      const modelConfigData = await fs.readFile(modelConfigPath, 'utf8');
      this.modelConfig = JSON.parse(modelConfigData);
      console.log(`ðŸ“„ Loaded model '${this.modelName}': ${this.modelConfig.vendor}/${this.modelConfig.model} (cost: $${this.modelConfig.cost}/1M tokens, minSimilarity: ${this.modelConfig.minSimilarity || 0.0})`);
      
      // Check if API key is provided for the vendor
      const apiKeyName = `${this.modelConfig.vendor.toUpperCase()}_API_KEY`;
      if (!process.env[apiKeyName]) {
        throw new Error(`${apiKeyName} environment variable is required. Please set it in a .env file.`);
      }
      
      this.apiKey = process.env[apiKeyName];
      this.embeddingService = new EmbeddingService(this.apiKey, this.modelConfig);
    } catch (error) {
      console.error(`âŒ Error loading model config for '${this.modelName}':`, error.message);
      throw error;
    }
  }

  async initialize() {
    // Load model configuration first
    await this.loadModelConfig();
    
    // Create or load the vector index from dataset folder with standard filename
    const indexFileName = 'index.json';
    this.index = new LocalIndex(this.indexPath, indexFileName);
    
    // Check if index exists
    const indexExists = await this.index.isIndexCreated();
    if (!indexExists) {
      throw new Error(`No embeddings index found for dataset '${this.dataset}' with model '${this.modelName}'. Please run generate first.`);
    }
  }

  async loadEvalData() {
    try {
      const evalPath = path.join(this.datasetPath, 'eval.json');
      const evalData = await fs.readFile(evalPath, 'utf8');
      return JSON.parse(evalData);
    } catch (error) {
      console.error(`Error loading eval.json from dataset ${this.dataset}:`, error.message);
      throw error;
    }
  }

  async search(query, topK = 3) {
    try {
      console.log(`Searching for: "${query}"`);
      
      // Track metrics for the search query
      const startTime = Date.now();
      
      // Generate embedding for the search query
      const result = await this.embeddingService.generateEmbedding(query);
      const queryEmbedding = result.embedding;
      const tokens = result.tokens; // Use API-provided token count
      
      const endTime = Date.now();
      const runtime = endTime - startTime;
      
      // Search the index - get more results initially to account for filtering
      const searchLimit = topK * 3; // Get 3x more results to have enough after filtering
      const results = await this.index.queryItems(queryEmbedding, searchLimit);
      
      // Filter results based on minSimilarity threshold
      const minSimilarity = this.modelConfig?.minSimilarity || 0.0;
      const filteredResults = results.filter(result => result.score >= minSimilarity);
      const belowThresholdResults = results.filter(result => result.score < minSimilarity);
      
      // When filtering by minSimilarity, show all results above threshold
      // Otherwise, limit to topK results
      const finalResults = minSimilarity > 0 ? filteredResults : filteredResults.slice(0, topK);
      
      if (minSimilarity > 0 && filteredResults.length < results.length) {
        console.log(`ðŸ” Filtered ${results.length - filteredResults.length} results below minSimilarity threshold (${minSimilarity})`);
      }
      
      const searchResults = finalResults.map(result => ({
        id: result.item.metadata.id,
        score: result.score,
        title: result.item.metadata.title,
        description: result.item.metadata.description
      }));
      
      // Get top 3 results below threshold for display
      const belowThresholdTop3 = belowThresholdResults.slice(0, 3).map(result => ({
        id: result.item.metadata.id,
        score: result.score,
        title: result.item.metadata.title,
        description: result.item.metadata.description
      }));
      
      // Return results with timing information
      return {
        results: searchResults,
        belowThresholdResults: belowThresholdTop3,
        metrics: {
          tokens: tokens,
          runtime: runtime
        }
      };
    } catch (error) {
      console.error('Error during search:', error.message);
      throw error;
    }
  }

  async runEvaluation() {
    console.log('Running evaluation...\n');
    const evalData = await this.loadEvalData();
    
    const results = [];
    
    for (const evalItem of evalData) {
      const searchResponse = await this.search(evalItem.search, 3);
      const searchResults = searchResponse.results;
      const belowThresholdResults = searchResponse.belowThresholdResults;
      const searchMetrics = searchResponse.metrics;
      
      const foundIds = searchResults.map(result => result.id);
      const expectedIds = evalItem.expected || [];
      
      // Calculate recall and precision
      const recall = Metrics.calculateRecall(foundIds, expectedIds);
      const precision = Metrics.calculatePrecision(foundIds, expectedIds);
      
      // Track evaluation metrics
      const foundSet = new Set(foundIds);
      const expectedFound = expectedIds.filter(id => foundSet.has(id)).length;
      const cost = this.embeddingService.calculateCost(searchMetrics.tokens);
      
      this.metrics.addEvaluateMetrics({
        search: evalItem.search,
        tokens: searchMetrics.tokens,
        runtime: searchMetrics.runtime,
        cost: cost,
        recall: recall,
        precision: precision,
        expectedCount: expectedIds.length,
        foundCount: expectedFound,
        returnedCount: foundIds.length
      });
      
      // Validate results
      const validation = Validator.validateResults(foundIds, expectedIds);
      
      console.log(`Search: "${evalItem.search}"`);
      console.log(`Expected: [${expectedIds.join(', ')}]`);
      console.log(`Found: [${foundIds.join(', ')}]`);
      console.log(`Validation: ${validation.isValid ? 'âœ…' : 'âŒ'} ${validation.message}`);
      console.log(`Metrics: Tokens: ${searchMetrics.tokens}, Runtime: ${searchMetrics.runtime}ms`);
      console.log(`Recall: ${recall.toFixed(1)}%, Precision: ${precision.toFixed(1)}%`);
      console.log(`Results above threshold (${searchResults.length}):`);
      
      searchResults.forEach((result, index) => {
        console.log(`  ${index + 1}. [ID: ${result.id}, Score: ${result.score.toFixed(4)}] ${result.title}`);
        console.log(`     ${result.description.substring(0, 100)}...`);
      });
      
      // Display top 3 results below threshold if they exist
      if (belowThresholdResults && belowThresholdResults.length > 0) {
        console.log(`Next results below threshold:`);
        belowThresholdResults.forEach((result, index) => {
          console.log(`  ${searchResults.length + index + 1}. [ID: ${result.id}, Score: ${result.score.toFixed(4)}] ${result.title}`);
          console.log(`     ${result.description.substring(0, 100)}...`);
        });
      }
      
      console.log('\n' + '-'.repeat(80) + '\n');
      
      results.push({
        search: evalItem.search,
        expected: expectedIds,
        found: foundIds,
        validation: validation,
        results: searchResults,
        metrics: {
          tokens: searchMetrics.tokens,
          runtime: searchMetrics.runtime,
          cost: 0.1,
          recall: recall,
          precision: precision
        }
      });
      
      // Small delay between searches
      await new Promise(resolve => setTimeout(resolve, 200));
    }
    
    // Display evaluation metrics totals
    const totals = this.metrics.getEvaluateTotals();
    console.log('\nðŸ“ˆ Evaluation Metrics Summary:');
    console.log(`  Total Queries: ${totals.queryCount}`);
    console.log(`  Total Tokens: ${totals.totalTokens}`);
    console.log(`  Total Runtime: ${totals.totalRuntime}ms`);
    console.log(`  Total Cost: $${totals.totalCost}`);
    console.log('\nðŸ“Š Recall & Precision Averages:');
    console.log(`  Micro-averaging: Recall ${totals.microAveraging.recall.toFixed(1)}%, Precision ${totals.microAveraging.precision.toFixed(1)}%`);
    console.log(`  Macro-averaging: Recall ${totals.macroAveraging.recall.toFixed(1)}%, Precision ${totals.macroAveraging.precision.toFixed(1)}%`);
    console.log(`  Weighted-averaging: Recall ${totals.weightedAveraging.recall.toFixed(1)}%, Precision ${totals.weightedAveraging.precision.toFixed(1)}%`);
    
    return results;
  }

  async generateEmbeddingsOnly() {
    try {
      console.log(`ðŸ”„ Generating embeddings for dataset '${this.dataset}' using model '${this.modelName}' and storing vectors...\n`);
      
      // Load model configuration first
      await this.loadModelConfig();
      
      const generator = new Generator(this.datasetPath, this.embeddingService, this.indexPath, this.modelName);
      const generatorMetrics = await generator.generate();
      
      // Merge generator metrics into our metrics if needed
      if (generatorMetrics && generatorMetrics.generateMetrics) {
        generatorMetrics.generateMetrics.forEach(metric => {
          this.metrics.addGenerateMetrics(metric);
        });
      }
      
    } catch (error) {
      console.error('âŒ Error generating embeddings:', error.message);
      process.exit(1);
    }
  }

  async evaluateOnly() {
    try {
      console.log(`ðŸ” Running evaluation for dataset '${this.dataset}' using model '${this.modelName}'...\n`);
      
      await this.initialize();
      
      // Check if index exists and has items
      const stats = await this.index.getIndexStats();
      if (stats.items === 0) {
        console.error(`âŒ No embeddings found for dataset '${this.dataset}'! Please run "npm run generate" first to create embeddings.`);
        console.log(`ðŸ’¡ Usage: npm run generate -- --dataset ${this.dataset} --model ${this.modelName}  # Then: npm run evaluate -- --dataset ${this.dataset} --model ${this.modelName}`);
        process.exit(1);
      } else {
        console.log(`ðŸ“Š Using existing index with ${stats.items} items.\n`);
      }
      
      // Run the evaluation only
      const results = await this.runEvaluation();
      
      // Prepare complete results with metrics
      const completeResults = {
        results: results,
        metrics: this.metrics.getAllMetrics().evaluate
      };
      
      // Save results to file in dataset folder with model name
      const resultsFileName = `evaluation-results-${this.modelName}.json`;
      const resultsPath = path.join(this.datasetPath, resultsFileName);
      await fs.writeFile(resultsPath, JSON.stringify(completeResults, null, 2));
      console.log(`âœ… Evaluation results saved to ${resultsPath}`);
      
      return results;
    } catch (error) {
      console.error('âŒ Error running evaluation:', error.message);
      process.exit(1);
    }
  }

  async run() {
    try {
      console.log(`Starting Embeddings Evaluator for dataset '${this.dataset}' using model '${this.modelName}'...\n`);
      
      await this.initialize();
      
      // Check if index is empty, if so build it
      const stats = await this.index.getIndexStats();
      if (stats.items === 0) {
        console.log('No embeddings found, generating first...');
        await this.generateEmbeddingsOnly();
        await this.initialize(); // Reinitialize after generating
      } else {
        console.log(`Using existing index with ${stats.items} items.\n`);
      }
      
      // Run the evaluation
      const results = await this.runEvaluation();
      
      // Prepare complete results with metrics
      const completeResults = {
        results: results,
        metrics: this.metrics.getAllMetrics().evaluate
      };
      
      // Save results to file in dataset folder with model name
      const resultsFileName = `evaluation-results-${this.modelName}.json`;
      const resultsPath = path.join(this.datasetPath, resultsFileName);
      await fs.writeFile(resultsPath, JSON.stringify(completeResults, null, 2));
      console.log(`Evaluation results saved to ${resultsPath}`);
      
      return results;
    } catch (error) {
      console.error('Error running evaluation:', error.message);
      process.exit(1);
    }
  }
}

// Run the evaluator if this file is executed directly
if (require.main === module) {
  (async () => {
  try {
    // Parse command line arguments
    const args = process.argv.slice(2);
    let command = 'run'; // default command
    let dataset = 'default'; // default dataset
    let modelName = 'default'; // default model
    
    // Parse arguments
    for (let i = 0; i < args.length; i++) {
      const arg = args[i];
      if (arg === '--dataset' && i + 1 < args.length) {
        dataset = args[i + 1];
        i++; // skip next argument as it's the dataset name
      } else if (arg === '--model' && i + 1 < args.length) {
        modelName = args[i + 1];
        i++; // skip next argument as it's the model name
      } else if (arg === 'generate' || arg === 'evaluate') {
        command = arg;
      }
    }
    
    // Validate dataset - check if dataset folder exists
    const datasetPath = path.join(__dirname, dataset);
    try {
      await fs.access(datasetPath);
      const stats = await fs.stat(datasetPath);
      if (!stats.isDirectory()) {
        throw new Error(`'${dataset}' is not a directory`);
      }
    } catch (error) {
      console.error(`âŒ Error: Dataset folder '${dataset}' does not exist.`);
      console.log('ðŸ’¡ Usage examples:');
      console.log('   npm start -- --dataset default --model default');
      console.log('   npm start -- --dataset courses-de --model oa3large');      
      console.log('   npm run generate -- --dataset courses-de --model default');
      console.log('   npm run evaluate -- --dataset default --model oa3large');
      console.log('');
      console.log('   Or run directly:');
      console.log('   node index.js --dataset default --model default');
      console.log('   node index.js generate --dataset courses-de --model oa3large');
      process.exit(1);
    }
    
    const evaluator = new EmbeddingsEvaluator(dataset, modelName);
    
    // Handle different commands
    switch (command) {
      case 'generate':
        console.log(`ðŸš€ Command: Generate embeddings and store vectors for dataset '${dataset}' using model '${modelName}'\n`);
        evaluator.generateEmbeddingsOnly();
        break;
      case 'evaluate':
        console.log(`ðŸš€ Command: Run evaluation for search terms in dataset '${dataset}' using model '${modelName}'\n`); 
        evaluator.evaluateOnly();
        break;
      default:
        console.log(`ðŸš€ Command: Full pipeline (generate + evaluate) for dataset '${dataset}' using model '${modelName}'\n`);
        evaluator.run();
        break;
    }
  } catch (error) {
    console.error('\nâŒ Error:', error.message);
    console.error('\nðŸ’¡ Please create a .env file with the required API key for your chosen model:');
    console.error('   For OpenAI models: OPENAI_API_KEY=your_openai_api_key_here');
    console.error('\nðŸ“– See .env.example for the template.');
    process.exit(1);
  }
  })();
}

module.exports = EmbeddingsEvaluator;